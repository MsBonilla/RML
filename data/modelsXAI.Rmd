---
title: "La Guía del Viajero al Aprendizaje Automático Responsable"
subtitle: "Con R, randomforest, mlr3 and DALEX"
author: "Przemyslaw Biecek & Anna Kozak"
date: "15.01.2022"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# *Capítulo 1: modelado predictivo*

Preparate

```         
install.packages(c("tableone", "DALEX", "ggplot2", "partykit", "mlr3", "mlr3learners", "ranger", "mlr3tuning", "paradox"))
```

# Parte 1: Introducción al modelado predictivo + AED

El propósito de este tutorial es presentar un ciclo de vida de un modelo predictivo único para un problema relacionado con la clasificación binaria (pero deliberadamente no menciono la regresión logística).
A lo largo del camino, abordaremos varios temas interesantes, como el entrenamiento de modelos, la verificación de modelos, el ajuste de hiperparámetros y el análisis exploratorio de modelos.

Los ejemplos presentados aquí están inspirados en tres libros de texto: [The Elements of Statistical Learning](https://www.statlearning.com/) with mathematical foundations, [The mlr3 book](https://mlr3book.mlr-org.com/), presenting software package `mlr3` designed for advanced model programming, [Explanatory Model Analysis](http://ema.drwhy.ai/) describe métodos para la exploración y visualización de modelos.
Tenga en cuenta que el modelaje responsable requiere conocimientos que no se pueden aprender en dos días.
Entonces, después de esta introducción, recomiendo encarecidamente que consultes estos libros.

*¿Por qué debería importarme?*

Los modelos predictivos se han utilizado a lo largo de toda la historia de la humanidad.
Los sacerdotes en Egipto predecían cuándo se produciría la inundación del Nilo o un eclipse solar.
Los avances en las estadísticas, el aumento de la disponibilidad de conjuntos de datos y el aumento de la potencia informática permiten construir modelos predictivos cada vez más rápido.

Hoy en día, los modelos predictivos se utilizan prácticamente en todas partes.
Planificar la cadena de suministro para una gran corporación, recomendar un almuerzo o una película para la noche o predecir atascos en una ciudad.
Los periódicos están llenos de aplicaciones interesantes.

Pero ¿cómo se desarrollan esos modelos predictivos?
En las siguientes secciones, repasaremos el ciclo de vida de un modelo predictivo.
Desde la fase de concepto, pasando por el diseño, la formación, la comprobación, hasta la implementación.
Para este ejemplo, utilizaremos el conjunto de datos sobre el riesgo de muerte de pacientes con Covid-19 después de la infección por SARS-COV-2.
Pero tenga en cuenta que los datos presentados aquí son artificiales.
Se genera para reflejar las relaciones en datos reales, pero no contiene observaciones reales para pacientes reales.
Aun así, debería ser un caso de uso interesante analizar la vida útil típica de un modelo predictivo.

*Herramientas*

Estos materiales se basan en dos paquetes de R: `mlr3` para entrenamiento de modelos y `DALEX` para visualización y explicación de modelos.
Pero hay más paquetes con funcionalidad similares, para modelar otras opciones populares son: `mlr`, `tidymodels` y `caret` mientras que para la explicación del modelo encontrarán muchas características interesantes en `flashlight` e `iml`.

*El Problema*

El ciclo de vida de un modelo predictivo comienza con un problema bien definido.
En este ejemplo, buscamos un modelo que evalúe el riesgo de muerte después de un diagnóstico de covid.
No queremos adivinar quién sobrevivirá y quién no.
Queremos construir una puntuación que nos permita clasificar a los pacientes por riesgo de muerte\footnote{Por esta razón, en las siguientes secciones usaremos la medida AUC para evaluar modelos}.

¿Por qué necesitamos un modelo así?
¡Podría tener muchas aplicaciones!
A quienes corren mayor riesgo de muerte se les podría dar más protección, como proporcionándoles oxímetros de pulso o vacunándolos preferentemente.

## Cargar Librerias

```{r, warning=FALSE, message=FALSE}
library("tableone")
library("DALEX")
library("ggplot2")
library("partykit")
library("mlr3")
library("mlr3learners")
library("ranger")
library("mlr3tuning")
library("paradox")

set.seed(1313)
```

## Concepción

Antes de construir cualquier modelo, incluso antes de tocar cualquier dato, primero debemos determinar con qué propósito construiremos un modelo predictivo.

Es muy importante definir el objetivo antes de sentarnos a programar, porque luego es fácil perderse en configurar parámetros de funciones y lidiar con todos esos detalles que necesitamos hacer.
Es fácil perder de vista el objetivo a largo plazo.

Entonces, primero: definir el objetivo.

A los efectos de estos ejercicios, he seleccionado datos sobre la pandemia de covid.
Imaginemos que queremos determinar el orden de vacunación.
En este ejemplo queremos crear un modelo predictivo que evalúe los riesgos individuales porque nos gustaría clasificar a los pacientes según su riesgo.

Para obtener un modelo que ofrezca la mejor clasificación, utilizaremos la medida AUC para evaluar el rendimiento del modelo.
Hablaré de qué es exactamente el AUC un poco más adelante; en este momento la clave es que estamos interesados en clasificar a los pacientes según su puntuación de riesgo.

## Leer los datos

Para construir un modelo necesitamos buenos datos.
En Machine Learning, la palabra *bueno* significa una gran cantidad de datos representativos.
Recopilar datos representativos no es fácil y, a menudo, requiere diseñar un experimento adecuado.

El mejor escenario posible es que se pueda diseñar y ejecutar un experimento para recopilar los datos necesarios.
En situaciones menos cómodas, buscamos "experimentos naturales", es decir, datos que han sido recopilados para otro propósito pero que pueden usarse para construir un modelo.
Aquí utilizaremos los datos recopilados a través de entrevistas epidemiológicas.
Habrá muchos puntos de datos y deberían ser bastante representativos, aunque desafortunadamente solo involucra a pacientes sintomáticos que dan positivo en la prueba del SARS-COV-2.

Para los fines de este ejercicio, he preparado dos conjuntos de características de los pacientes infectados con covid.
Es importante tener en cuenta que estos no son datos reales de pacientes.
Se trata de datos simulados, generados para tener relaciones consistentes con datos reales (obtenidos de los NIH), pero los datos en sí no son reales.
Afortunadamente, son suficientes para los propósitos de nuestro ejercicio.

Los datos se dividen en dos conjuntos `covid_spring` y `covid_summer`.
El primero se adquiere en la primavera de 2020 y se utilizará como datos de entrenamiento, mientras que el segundo conjunto de datos se adquiere en verano y se utilizará para la validación.
En el aprendizaje automático, la validación del modelo se realiza en un conjunto de datos separado.
Esto controla el riesgo de sobreajustar un modelo elástico a los datos.
Si no tenemos un conjunto separado, se genera mediante técnicas de validación cruzada, fuera de muestra o fuera de tiempo.

-   `covid_spring.csv` Corresponde a los datos de mortalidad por covid de la primavera de 2020. Usaremos estos datos para el entrenamiento del modelo.
-   `covid_summer.csv` Corresponde a los datos de mortalidad por covid del verano de 2020. Usaremos estos datos para la validación del modelo.

```{r, warning=FALSE, message=FALSE}
covid_spring <- read.table("covid_spring.csv", sep =";", header = TRUE, stringsAsFactors = TRUE)
covid_summer <- read.table("covid_summer.csv", sep =";", header = TRUE, stringsAsFactors = TRUE)
```

## Explorar los datos

Antes de comenzar con cualquier modelado serio, vale la pena mirar primero los datos.
Para ello haremos un EDA sencillo.
En R hay muchas herramientas para realizar exploración de datos, valoro los paquetes que admiten la llamada tabla uno.

```{r, warning=FALSE, message=FALSE}
library("tableone")

table1 <- CreateTableOne(vars = colnames(covid_spring)[1:11],
                         data = covid_spring,
                         strata = "Death")
print(table1)
```

Durante el modelado, la exploración suele llevar más tiempo.
En este caso nos limitaremos a algunos gráficos sencillos.

```{r, warning=FALSE, message=FALSE}
ggplot(covid_spring, aes(Age)) +
  geom_histogram() +
  ggtitle("Histograma de edad")

ggplot(covid_spring, aes(Age, fill = Death)) +
  geom_histogram() +
  ggtitle("Histograma de edad")

ggplot(covid_spring, aes(Age, fill = Death)) +
  geom_histogram(color = "white") +
  ggtitle("Histograma de edad") + 
  DALEX::theme_ema() +
  scale_fill_manual("", values = c("grey", "red3"))

library(ggmosaic)
ggplot(data = covid_spring) + 
  geom_mosaic(aes(x=product(Diabetes), fill = Death)) + 
  DALEX::theme_ema() +
  scale_fill_manual("", values = c("grey", "red3"))


```

```{r, warning=FALSE, message=FALSE, fig.width=8, fig.height=12}
library("pheatmap")
pheatmap((covid_spring[,3:11] == "Yes") + 0)

```

## Tranformar los datos

Una de las reglas más importantes a recordar al construir un modelo predictivo es: ¡No condiciones el futuro!

Variables como "Hospitalización" o "Tos" no son buenos predictores porque no se conocen de antemano.

```{r, warning=FALSE, message=FALSE}
covid_spring <- covid_spring[,c("Gender", "Age", "Cardiovascular.Diseases", "Diabetes",
               "Neurological.Diseases", "Kidney.Diseases", "Cancer",
               "Death")]
covid_summer <- covid_summer[,c("Gender", "Age", "Cardiovascular.Diseases", "Diabetes",
               "Neurological.Diseases", "Kidney.Diseases", "Cancer",
               "Death")]
```

## Tu turno

-   Grafíca la distribución de la edad para `covid_spring` y `covid_summer`.
-   Calcula `tableone` para `covid_spring` y `covid_summer`.
-   (extra) En la librería `DALEX` Encontraras la base de datos `titanic_imputed`. Calcule `tableone` para esta tabla de datos.

```{r}

ggplot(covid_summer, aes(Age)) +
  geom_histogram() +
  ggtitle("Histograma de edad")


table2 <- CreateTableOne(vars = colnames(covid_summer)[1:11],
                         data = covid_summer,
                         strata = "Death")
print(table2)
```

```{r}
library(DALEX)
data(titanic_imputed)
library(tableone)
table3 <- CreateTableOne(vars = colnames(titanic_imputed)[1:8],
                         data = titanic_imputed,
                         strata = "survived")

print(table3)
```

# Parte 2: ¡Hola modelo! Primer modelo predictivo + Cómo medir el desempeño

Pensaremos en un modelo predictivo como una función que calcula una determinada predicción para determinados datos de entrada.
Por lo general, dicha función se crea automáticamente en función de los datos.
Pero técnicamente el modelo puede ser cualquier función definida de cualquier forma.
El primer modelo se basará en las estadísticas recopiladas por los CDC (CDC significa Centros para el Control y la Prevención de Enfermedades). Encontrará un conjunto de estadísticas útiles relacionadas con la mortalidad por Covid en [this page](%7Bhttps://tinyurl.com/CDCmortality)) que determinan la mortalidad en diferentes grupos de edad.

En muchos casos, no se necesitan datos para crear un modelo.
Simplemente busque en Google información sobre el problema.

Resulta que los CDC tienen algunas estadísticas decentes sobre la mortalidad relacionada con la edad.
Estas estadísticas serán suficientes como una primera aproximación de nuestro modelo.

<https://www.cdc.gov/coronavirus/2019-ncov/covid-data/investigations-discovery/hospitalization-death-by-age.html>

*Lección 1:* A menudo no se necesitan datos individuales para construir un buen modelo.

## Crear un modelo

¿Qué es un modelo predictivo?
Lo consideraremos como una función que toma un conjunto de números como entrada y devuelve un único número como resultado 
- la puntuación.

```{r, warning=FALSE, message=FALSE}
cdc_risk <- function(x, base_risk = 0.00003) {
  multip <- rep(7900, nrow(x))
  multip[which(x$Age < 84.5)] <- 2800
  multip[which(x$Age < 74.5)] <- 1100
  multip[which(x$Age < 64.5)] <- 400
  multip[which(x$Age < 49.5)] <- 130
  multip[which(x$Age < 39.5)] <- 45
  multip[which(x$Age < 29.5)] <- 15
  multip[which(x$Age < 17.5)] <- 1
  multip[which(x$Age < 4.5)]  <- 2
  multip * base_risk
}
x <- data.frame(Age = 25, Hospitalisation = "Yes")
cdc_risk(x)


library("DALEX")
model_cdc <-  DALEX::explain(cdc_risk,
                   predict_function = function(m, x) m(x),
                   type  = "classification",
                   label = "CDC")
predict(model_cdc, x)

```

La misma función se puede escribir en una forma un poco más compacta como (ahora funciona en muchas filas)

```{r, warning=FALSE, message=FALSE}
cdc_risk <- function(x, base_risk = 0.00003) {
  bin <- cut(x$Age, c(-Inf, 4.5, 17.5, 29.5, 39.5, 49.5, 64.5, 74.5, 84.5, Inf))
  relative_risk <- c(2, 1, 15, 45, 130, 400, 1100, 2800, 7900)[as.numeric(bin)] 
  relative_risk * base_risk
}

# check it
x <- data.frame(Age = c(25,45,85))
cdc_risk(x)

summary(cdc_risk(covid_spring))

table(Death = covid_spring$Death, 
      Prediction.above.005 = cdc_risk(covid_spring) > 0.05)
```

## envolver el modelo

En R tenemos muchas herramientas para crear modelos.
El problema con ellos es que estas herramientas son creadas por diferentes personas y devuelven resultados en diferentes estructuras.
Entonces, para trabajar de manera uniforme con los modelos, necesitamos empaquetar el modelo de tal manera que tenga una interfaz uniforme.

Los diferentes modelos tienen diferentes API.

¡Pero necesitas una API para gobernarlos a todos!

La biblioteca DALEX proporciona una arquitectura unificada para explorar y validar modelos utilizando diferentes métodos analíticos.

[Mayor información](http://ema.drwhy.ai/do-it-yourself.html#infoDALEX)

```{r, warning=FALSE, message=FALSE}
library("DALEX")
model_cdc <-  DALEX::explain(cdc_risk,
                   predict_function = function(m, x) m(x),
                   data  = covid_summer,
                   y     = covid_summer$Death == "Yes",
                   type  = "classification",
                   label = "CDC")
predict(model_cdc, x)
```

## Rendimiento del modelo

La evaluación del desempeño del modelo para la clasificación se basa en medidas diferentes a las de la regresión.

Para la regresión, las medidas comúnmente utilizadas son Error cuadrático medio MSE

$$MSE(f) = \frac{1}{n} \sum_{i}^{n} (f(x_i) - y_i)^2 $$

y error cuadrático medio raíz RMSE

$$RMSE(f) = \sqrt{MSE(f, X, y)} $$

Para la clasificación, las medidas comúnmente utilizadas son Precisión

$$ACC(f) = (TP + TN)/n$$

Precisión

$$Prec(f) = TP/(TP + FP)$$

y recordar

$$Recall(f) = TP/(TP + FN)$$

y F1 score

$$F1(f) = 2\frac{Prec(f)  * Recall(f) }{Prec(f)  + Recall(f)}$$

En este problema nos interesa la clasificación de puntuaciones, por lo que usaremos la medida AUC (el área bajo la curva ROC).

Existen muchas medidas para evaluar modelos predictivos y están ubicadas en varios paquetes de R. (`ROCR`, `measures`, `mlr3measures`, etc.).
Para simplificar, en este ejemplo utilizamos solo la medida AUC del paquete `DALEX`.

Pregnancy: Sensitivity and Specificity

<http://getthediagnosis.org/diagnosis/Pregnancy.htm>

<https://en.wikipedia.org/wiki/Sensitivity_and_specificity>

Para las AUC el `cutoff` no importa.
Pero lo configuramos para obtener una buena precisión y F1.

[Mayor información](http://ema.drwhy.ai/modelPerformance.html#modelPerformanceMethodBin)

*Rendimiento del modelo*

La exploración del modelo comienza con una evaluación de qué tan bueno es el modelo.
La función `DALEX::model_performance` Es la función que calcula un conjunto de las medidas más comunes para el modelo especificado.

```{r, warning=FALSE, message=FALSE}
library("DALEX")
model_cdc <-  DALEX::explain(cdc_risk,
                   predict_function = function(m, x) m(x),
                   type  = "classification",
                   label = "CDC")
predict(model_cdc, x)

model_cdc <-  update_data(model_cdc,
                   data  = covid_summer[,-8],
                   y     = covid_summer$Death == "Yes")
predict(model_cdc, x)

#library(ROCR)
mp_cdc <- model_performance(model_cdc, cutoff = 0.1)
mp_cdc
```

### ROC

Nota: El modelo se evalúa con los datos proporcionados en el explicador.
Usa `DALEX::update_data()` para especificar otro conjunto de datos.

Nota: El explicador sabe si el modelo es para clasificación o regresión, por lo que selecciona automáticamente las medidas correctas.
Se puede anular si es necesario.

La función genérica `plot` de S3 dibuja un resumen gráfico del rendimiento del modelo.
Con el argumento `geom`, se puede determinar el tipo de gráfico.

[Mayor información](http://ema.drwhy.ai/modelPerformance.html#fig:exampleROC)

```{r, warning=FALSE, message=FALSE, fig.width=3, fig.height=3}
plot(mp_cdc, geom = "roc") + DALEX::theme_ema() 
```

### ELEVAR

[Mayor información](http://ema.drwhy.ai/modelPerformance.html#fig:examplePRC)

```{r, warning=FALSE, message=FALSE, fig.width=3, fig.height=3}
plot(mp_cdc, geom = "lift")
```

```{r, warning=FALSE, message=FALSE, fig.width=3, fig.height=3}
plot(mp_cdc, geom = "boxplot")
```

## Tú turno

-   Calcule el AUC para el modelo CDC en los datos de `covid_spring`.
-   Trazar la ROC para los datos `covid_spring` y `covid_summer`.
-   (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Construya un modelo similar al CDC pero para el conjunto de datos del Titanic. ¿Qué tan bueno es tu modelo?

# Parte 3: Conceptos básicos del árbol de decisión y el bosque aleatorio.

Normalmente, no sabemos qué función es la mejor para nuestro problema.
Es por eso que queremos utilizar datos para encontrar/entrenar dicha función con el uso de algún algoritmo automatizado.

En Machine Learning, hay cientos de algoritmos disponibles.
Por lo general, este entrenamiento se reduce a encontrar parámetros para alguna familia de modelos.
Una de las familias de modelos más populares son los árboles de decisión.
Su gran ventaja es la transparencia de su estructura.

Comenzaremos a construir el modelo construyendo un árbol de decisión.
Controlaremos paso a paso la complejidad del modelo.

[Mayor información](https://cran.r-project.org/web/packages/partykit/vignettes/ctree.pdf)

```{r, warning=FALSE, message=FALSE, fig.width=9, fig.height=5}
library("partykit")

tree1 <- ctree(Death ~., covid_spring, 
              control = ctree_control(maxdepth = 1))
plot(tree1)

tree2 <- ctree(Death ~., covid_spring, 
              control = ctree_control(maxdepth = 2))
plot(tree2)

tree3 <- ctree(Death ~., covid_spring, 
              control = ctree_control(maxdepth = 3))
plot(tree3)


tree <- ctree(Death ~., covid_spring, 
              control = ctree_control(alpha = 0.0001))
plot(tree)
```

Para trabajar con diferentes modelos de manera uniforme, también incluiremos este en una explicación.

```{r, warning=FALSE, message=FALSE}
model_tree <-  DALEX::explain(tree,
                   predict_function = function(m, x) predict(m, x, type = "prob")[,2],
                   data = covid_summer[,-8],
                   y = covid_summer$Death == "Yes",
                   type = "classification",
                   label = "Tree",
                   verbose = FALSE)
```

### Prueba tu modelo

```{r, warning=FALSE, message=FALSE}
mp_tree <- model_performance(model_tree, cutoff = 0.1)
mp_tree
plot(mp_tree, geom = "roc")

hist(predict(model_tree, covid_summer))

plot(mp_tree, mp_cdc, geom = "roc")
```

### Tú turno

-   Verifique las AUC para el modelo CDC en los datos `covid_spring`.
-   Trazar ROC para los datos `covid_spring` y `covid_summer`.
-   (\*)Intenta sobreajustar.

Ejemplo para titanic

```         
head(titanic_imputed)
tree <- ctree(survived ~., titanic_imputed)
plot(tree)

tree <- ctree(factor(survived) ~., titanic_imputed, 
              control = ctree_control(alpha = 0.0001))
plot(tree)

model_tree <-  DALEX::explain(tree,
                   predict_function = function(m, x) predict(m, x, type = "prob")[,2],
                   data = titanic_imputed,
                   y = titanic_imputed$survived == 1,
                   type = "classification",
                   label = "Tree",
                   verbose = FALSE)
mp <- model_performance(model_tree)
mp
plot(mp, geom = "roc")
```

## plantar un bosque

Los árboles de decisión son modelos que tienen un sesgo bajo pero una varianza alta.
En 2001, Leo Breiman propuso una nueva familia de modelos, llamada bosque aleatorio, que promedia las puntuaciones de múltiples árboles de decisión entrenados con muestras de datos de arranque.
Todo el algoritmo es un poco más complejo pero también muy fascinante.
Puedes leer sobre esto en <https://tinyurl.com/RF2001>.
Hoy en día, una técnica muy popular, en cierto sentido complementaria, para mejorar modelos es el impulso, en el que se reduce la carga del modelo a expensas de la variación.
Este algoritmo reduce la varianza a expensas del sesgo.
Muy a menudo conduce a un modelo mejor.

Entrenaremos un bosque aleatorio con la biblioteca `mlr3`.
El primer paso es definir la tarea de predicción.
[Mayor información](https://mlr3book.mlr-org.com/tasks.html)

```{r bagging_tree, warning=FALSE, message=FALSE}
library("mlr3")

covid_task <- TaskClassif$new(id = "covid_spring",
                             backend = covid_spring,
                             target = "Death",
                             positive = "Yes")
covid_task
```

Ahora falta definir la familia de modelos en la que queremos buscar una solución.
Los bosques aleatorios se especifican mediante el parámetro `classif.ranger"`. Para encontrar el mejor modelo en esta familia usamos `train()`.

[Mayor información](https://mlr3book.mlr-org.com/learners.html)

```{r, warning=FALSE, message=FALSE}
library("mlr3learners")
library("ranger")

covid_ranger <- lrn("classif.ranger", predict_type = "prob",
                num.trees = 25)
covid_ranger

covid_ranger$train(covid_task)
covid_ranger$model
predict(covid_ranger, covid_summer[1:3,], predict_type = "prob")[,1]

```

### prueba tu modelo

Un modelo entrenado se puede convertir en un explicador.
Se pueden utilizar funciones más simples para calcular el rendimiento de este modelo.
Pero utilizar explicadores tiene una ventaja que se verá en toda su belleza en sólo dos páginas.

```{r, warning=FALSE, message=FALSE}
model_ranger <-  explain(covid_ranger,
                           predict_function = function(m,x)
                                predict(m, x, predict_type = "prob")[,1],
                           data = covid_summer[,-8],
                           y = covid_summer$Death == "Yes",
                           type = "classification",
                           label = "Ranger",
                           verbose = FALSE)

mp_ranger <- model_performance(model_ranger)
mp_ranger
plot(mp_ranger, geom = "roc")

plot(mp_ranger, mp_tree, mp_cdc, geom = "roc")
```

## tú turno

-   Verifique las AUC para el modelo Ranger en los datos "covid_spring".
-   Trazar ROC para los datos `covid_spring` y `covid_summer`.
-   (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Cree un modelo basado en árbol para el conjunto de datos del Titanic. ¿Qué tan bueno es tu modelo?

# Parte 4: Optimización de hiperparámetros + resumen

*Optimización de hiperparámetros*

Los algoritmos de aprendizaje automático suelen tener muchos hiperparámetros que determinan cómo se debe entrenar el modelo.
Para modelos con alta varianza, la selección de dichos hiperparámetros tiene un fuerte impacto en la calidad de la solución final.
El paquete mlr3tuning contiene procedimientos para automatizar el proceso de búsqueda de buenos hiperparámetros.

ver: <https://mlr3book.mlr-org.com/tuning.html>.

Para usarlo, debe especificar el espacio del hiperparámetro para buscar.
No vale la pena optimizar todos los hiperparámetros.
En el siguiente ejemplo, nos centramos en cuatro para el algoritmo de bosque aleatorio.

## Optimización automatizada de hiperparámetros

Para la búsqueda automática de hiperparámetros, es necesario especificar algunos elementos más: (1) un criterio de parada, debajo está el número de 10 evaluaciones, (2) una estrategia de búsqueda para el espacio de parámetros, debajo está una búsqueda aleatoria, ( 3) una forma de evaluar el desempeño de los modelos propuestos, a continuación se encuentra el AUC determinado mediante validación cruzada quíntuple.

### Definir el espacio de búsqueda

Para poder buscar automáticamente los parámetros óptimos, primero es necesario especificar cuál es el espacio de posibles hiperparámetros.

[Mayor información](https://mlr3book.mlr-org.com/searchspace.html)

```{r, warning=FALSE, message=FALSE}
library("mlr3tuning")
library("paradox")

covid_ranger$param_set

search_space = ps(
  num.trees = p_int(lower = 50, upper = 500),
  max.depth = p_int(lower = 1, upper = 10),
  mtry = p_int(lower = 1, upper = 7),
  minprop = p_dbl(lower = 0.01, upper = 0.1),
  splitrule = p_fct(levels = c("gini", "extratrees"))
)
search_space
```

### Configurar el sintonizador

Las estrategias de búsqueda populares son `random_search` y `grid_search`.
La terminación se establece en un número específico de evaluaciones.
Las pruebas internas se basan en CV quíntuple.

[Mayor información](https://mlr3book.mlr-org.com/tuning.html#autotuner)

```{r, warning=FALSE, message=FALSE}
tuned_ranger = AutoTuner$new(
  learner    = covid_ranger,
  resampling = rsmp("cv", folds = 5),
  measure    = msr("classif.auc"),
  search_space = search_space,
  terminator = trm("evals", n_evals = 10),
  tuner    = tnr("random_search")
)
tuned_ranger
```

### Afinar

```{r, warning=FALSE, message=FALSE, results='hide'}
tuned_ranger$train(covid_task)
```

```{r, warning=FALSE, message=FALSE}
tuned_ranger$tuning_result
tuned_ranger$predict_newdata(newdata = covid_spring)$prob[1:4,]
```

### Prueba tu modelo

```{r, message=FALSE, warning=FALSE}
model_tuned <-  explain(tuned_ranger,
                           predict_function = function(m,x)
                               m$predict_newdata(newdata = x)$prob[,1],
                           data = covid_summer[,-8],
                           y = covid_summer$Death == "Yes",
                           type = "classification",
                           label = "AutoTune",
                           verbose = FALSE)

mp_tuned <- model_performance(model_tuned)
mp_tuned
plot(mp_tuned, geom = "roc")

plot(mp_ranger, mp_tree, mp_cdc, mp_tuned, geom = "roc")
```

### Resumir

```{r, message=FALSE, warning=FALSE}
do.call(rbind, 
        list(cdc   = mp_cdc$measures,
            tree   = mp_tree$measures,
            ranger = mp_ranger$measures,
            tuned  = mp_tuned$measures))
```

### Tu turno

-   Verifique el AUC para el modelo AutoTune en los datos `covid_spring`.
-   Trazar ROC para los datos `covid_spring` y `covid_summer`.
- (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Optimice un modelo basado en árbol para el conjunto de datos del Titanic. ¿Qué tan bueno es tu modelo?

# *Capítulo 2: Exploración del modelo*

Dedicaremos el segundo día por completo a hablar sobre métodos de exploración de modelos.

[Mayor información](http://ema.drwhy.ai/modelLevelExploration.html)

![DALEX piramide](DALEXpiramide.png)

# Parte 1: Análisis a nivel de modelo: importancia de la variable

Algunos modelos tienen métodos incorporados para evaluar la importancia de la variable.
Para modelos lineales se pueden utilizar coeficientes de modelo estandarizados o valores p.
Para bosques aleatorios, se puede utilizar el error de clasificación fuera de bolsa.
Para los modelos de impulso de árboles se pueden utilizar estadísticas de ganancia.
Sin embargo, el problema con tales medidas es que no todos los modelos tienen estadísticas de importancia variable incorporadas (por ejemplo, redes neuronales) y que las puntuaciones entre diferentes modelos no se pueden comparar directamente (cómo comparar las ganancias con los valores p).

Es por eso que necesitamos un enfoque independiente del modelo que sea comparable entre diferentes modelos.
El procedimiento que se describe a continuación es universal, independiente del modelo y no depende de la estructura del modelo.

El procedimiento se basa en perturbaciones variables en los datos de validación.
Si una variable es importante en un modelo, luego de su permutación las predicciones del modelo deberían ser menos precisas.

La importancia de la variable basada en permutación de una variable $i$ es la diferencia entre el rendimiento del modelo para los datos originales y el rendimiento del modelo medido en datos con la variable permutada $i$

$$
VI(i) = L(f, X^{perm(i)}, y) - L(f, X, y)
$$

donde $L(f, X, y)$ es el valor de la función de pérdida para los datos originales $X$, las etiquetas verdaderas $y$ y el modelo $f$, mientras que $X^{perm(i)}$ es el conjunto de datos $x $ con $i$-ésima variable permutada.

¿Qué medida de desempeño debería elegir?
Tu decides.
En la biblioteca `DALEX`, de forma predeterminada, RMSE se usa para regresión y 1-AUC para problemas de clasificación.
Pero puede cambiar la función de pérdida especificando el \verb:loss_function: argument.

[Mayor información](http://ema.drwhy.ai/featureImportance.html)

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=3}
mpart_ranger <- model_parts(model_ranger)
mpart_ranger
plot(mpart_ranger, show_boxplots = FALSE, bar_width=4) +
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("Variable importance","")
```

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=3}
mpart_ranger <- model_parts(model_ranger, type = "difference")
mpart_ranger
plot(mpart_ranger, show_boxplots = FALSE, bar_width=4) +
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("Variable importance","")
```

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=7}
mpart_cdc <- model_parts(model_cdc)
mpart_tree <- model_parts(model_tree)
mpart_ranger <- model_parts(model_ranger)
mpart_tuned <- model_parts(model_tuned)

plot(mpart_cdc, mpart_tree, mpart_ranger, mpart_tuned, show_boxplots = FALSE, bar_width=4) +
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("Variable importance","") +
  facet_wrap(~label, ncol = 2, scales = "free_y")

plot(mpart_cdc, mpart_tree, mpart_ranger, mpart_tuned, show_boxplots = FALSE, bar_width=4) +
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("Variable importance","")
```

## Tu turno

-   Compare los resultados de `covid_summer` con los resultados de los datos de `covid_spring`.
-   (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Entrene un modelo de guardabosques y calcule la importancia de la variable.

# Parte 2: Análisis a nivel de modelo: perfil variable

Los perfiles de dependencia parcial son promedios de los perfiles de CP para todas (o un número suficientemente grande) de observaciones.

La función `model_profiles()` calcula los perfiles de PD para a\~specified modelo y variables (todo por defecto).

[Mayor información](http://ema.drwhy.ai/partialDependenceProfiles.html)

```{r, message=FALSE, warning=FALSE}
mprof_cdc <- model_profile(model_cdc, "Age")
plot(mprof_cdc)

mgroup_ranger <- model_profile(model_ranger, variable_splits = list(Age = 0:100))
plot(mgroup_ranger)+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("PD profile","")
```

*Perfiles de dependencia parcial agrupados*

De forma predeterminada, el promedio se calcula para todas las observaciones.
Pero con el argumento `groups=` se puede especificar una variable de factor en la que se promediarán los perfiles de CP.

```{r, message=FALSE, warning=FALSE}
mgroup_ranger <- model_profile(model_ranger, variable_splits = list(Age = 0:100), groups = "Diabetes")
plot(mgroup_ranger)+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("PD profiles for groups","") + ylab("") + theme(legend.position = "top")


mgroup_ranger <- model_profile(model_ranger, variable_splits = list(Age = 0:100), groups = "Cardiovascular.Diseases")
plot(mgroup_ranger)+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("PDP variable profile","") + ylab("") + theme(legend.position = "top")

mgroup_ranger <- model_profile(model_ranger, "Age", k = 3, center = TRUE)
plot(mgroup_ranger)+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("PD profiles for segments","")

mgroup_ranger <- model_profile(model_ranger, "Age", groups = "Cardiovascular.Diseases")
plot(mgroup_ranger)+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0)) +
  ggtitle("Variable profile","")

mgroup_ranger <- model_profile(model_ranger, variable_splits = list(Age = 0:100), groups = "Cardiovascular.Diseases")
plot(mgroup_ranger, geom = "profiles")
plot(mgroup_ranger, geom = "points")
```

```{r, message=FALSE, warning=FALSE}
mprof_cdc <- model_profile(model_cdc, variable_splits = list(Age=0:100))
mprof_tree <- model_profile(model_tree, variable_splits = list(Age=0:100))
mprof_ranger <- model_profile(model_ranger, variable_splits = list(Age=0:100))
mprof_tuned <- model_profile(model_tuned, variable_splits = list(Age=0:100))
```

Luego se pueden dibujar perfiles con la función `plot()`.

```{r, message=FALSE, warning=FALSE}
plot(mprof_tuned, mprof_cdc, mprof_tree, mprof_ranger) +
  ggtitle("","") +
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0), legend.position = "top")
```

Si el modelo es aditivo, todos los perfiles CP son paralelos.
Pero si el modelo tiene interacciones, los perfiles de CP pueden tener diferentes formas para diferentes observaciones.
Definir el argumento k permite encontrar y calcular el promedio en k segmentos de perfiles CP.

Los perfiles PDP no tienen en cuenta la estructura de correlación entre las variables.
Para variables correlacionadas, el supuesto Ceteris paribus puede no tener sentido.
La función `model_profile` también puede calcular otros tipos de agregados, como perfiles marginales y perfiles locales acumulados.
Para hacer esto, especifique el argumento `type=` para `"condicional"` o `"acumulado"`.

## Tu turno

-   Compare los resultados de `covid_summer` con los resultados de los datos de `covid_spring`.
-   (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Entrene un modelo de guardabosques y trace perfiles variables.

# Parte 3: Análisis a nivel de instancia: atribuciones variables

Una vez que calculamos la predicción del modelo, a menudo surge la pregunta de qué variables tuvieron el mayor impacto en ella.

Para los modelos lineales es fácil evaluar el impacto de variables individuales porque hay un coeficiente para cada variable.

[Mayor información](http://ema.drwhy.ai/InstanceLevelExploration.html)

```{r}
Steve <- data.frame(Gender = factor("Male", c("Female", "Male")),
       Age = 76,
       Cardiovascular.Diseases = factor("Yes", c("No", "Yes")), 
       Diabetes = factor("No", c("No", "Yes")), 
       Neurological.Diseases = factor("No", c("No", "Yes")), 
       Kidney.Diseases = factor("No", c("No", "Yes")), 
       Cancer = factor("No", c("No", "Yes")))
predict(model_ranger, Steve)
Steve
```

Resulta que dichas atribuciones se pueden calcular para cualquier modelo predictivo.
El método independiente del modelo más popular son los valores de Shapley.
Se pueden calcular con una función `predict_parts()`.

[Mayor información](http://ema.drwhy.ai/shapley.html)

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=2.5}
ppart_cdc <- predict_parts(model_cdc, Steve, type = "shap")
plot(ppart_cdc)

ppart_tree <- predict_parts(model_tree, Steve, type = "shap")
plot(ppart_tree)

ppart_tree <- predict_parts(model_tree, Steve)
plot(ppart_tree)


ppart_ranger <- predict_parts(model_ranger, Steve, type = "shap")
pl1 <- plot(ppart_ranger) + ggtitle("Shapley values for Ranger")+
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))

ppart_ranger <- predict_parts(model_ranger, Steve)
pl2 <- plot(ppart_ranger) + ggtitle("Break-down for Ranger")+
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))

library("patchwork")
pl1 + (pl2 + scale_y_continuous("prediction", limits = c(0,0.4)))

ppart_ranger <- predict_parts(model_ranger, Steve,
                    keep_distributions = TRUE)
plot(ppart_ranger, plot_distributions = TRUE) + ggtitle("Consecutive conditoning for Ranger")+
  DALEX:::theme_ema_vertical() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))


ppart_tuned <- predict_parts(model_tuned, Steve, type = "shap")
plot(ppart_tuned)
```

El argumento `show_boxplots` le permite resaltar las barras de estabilidad de las atribuciones estimadas.

Otros valores posibles del argumento `type` son `oscillations`, `shap`, `break_down`, `break_down_interactions`.

Con `order` se puede forzar una determinada secuencia de variables.

De forma predeterminada, funciones como `model_parts`, `predict_parts`, `model_profiles` no calculan estadísticas sobre todo el conjunto de datos, sino sobre `n_samples` de casos aleatorios, y todo el procedimiento se repite `B` veces para estimar el error.

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=2.5}
ppart_cdc <- predict_parts(model_cdc, Steve)
plot(ppart_cdc)
```

```{r, message=FALSE, warning=FALSE, fig.width=6, fig.height=2.5}
ppart_tuned <- predict_parts(model_tuned, Steve)
plot(ppart_tuned)
```

## Tu turno

-   Compare los resultados de `covid_summer` con los resultados de los datos de `covid_spring`.
- (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Entrene un modelo de guardabosques y calcule la atribución de variables locales.

# Parte 4: Análisis a nivel de instancia: perfil variable + Resumen

*Perfil para una sola predicción*

Ceteris Paribus es una frase latina que significa "en igualdad de condiciones".

Los perfiles ceteris-paribus muestran cómo cambiaría a\~selected observada si una de las coordenadas de esa observación se cambió mientras se dejaban las otras coordenadas sin cambios.

La función `predict_profiles()` calculó perfiles de CP para una observación, modelo y vector de variables seleccionados (todas las variables continuas de forma predeterminada).

[Mayor información](http://ema.drwhy.ai/ceterisParibus.html)

```{r, message=FALSE, warning=FALSE}
mprof_cdc <- predict_profile(model_cdc, Steve, "Age")
plot(mprof_cdc)
```

Los perfiles CP se pueden visualizar con la función genérica \verb'plot()'

Por motivos técnicos, las variables cuantitativas y cualitativas no se pueden mostrar en un único gráfico.
Entonces, si desea mostrar la importancia de las variables de calidad, debe trazarlas por separado.

```{r, message=FALSE, warning=FALSE}
mprof_cdc <- predict_profile(model_cdc, variable_splits = list(Age=0:100), Steve)
mprof_tree <- predict_profile(model_tree, variable_splits = list(Age=0:100), Steve)
mprof_ranger <- predict_profile(model_ranger, variable_splits = list(Age=0:100), Steve)
mprof_tuned <- predict_profile(model_tuned, variable_splits = list(Age=0:100), Steve)

plot(mprof_tuned)

plot(mprof_tuned, mprof_cdc, mprof_tree, mprof_ranger)


mprof_tuned <- predict_profile(model_tuned, variables = "Age", Steve)
pl1 <- plot(mprof_tuned) + ggtitle("Ceteris paribus for Ranger")+
  DALEX:::theme_ema() + scale_y_continuous("prediction", limits = c(0,0.55)) +
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))

mprof_tuned2 <- predict_profile(model_tuned, variables = "Cardiovascular.Diseases", Steve)
pl2 <- plot(mprof_tuned2, variable_type = "categorical", variables = "Cardiovascular.Diseases", categorical_type = "lines")  + ggtitle("Ceteris paribus for Ranger")+
  DALEX:::theme_ema() +  scale_y_continuous("prediction", limits = c(0,0.55)) +
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))

pl1 + pl2

plot(mprof_tuned, mprof_cdc, mprof_tree, mprof_ranger) + ggtitle("Ceteris paribus for Steve")+
  DALEX:::theme_ema() + 
  theme( axis.text = element_text(color = "black", size = 12, hjust = 0))

```

La importancia local de las variables se puede medir como oscilaciones de los gráficos de CP.
Cuanto mayor es la variabilidad del perfil de PC, más importante es la variable.
Establezca `type = "oscillations"` en la función `predict_parts`.

## Tu turno

-   Compare los resultados de `covid_summer` con los resultados de los datos de `covid_spring`.
- (extra) En el paquete `DALEX` encontrará el conjunto de datos `titanic_imputed`. Entrene un modelo de guardabosques y calcule perfiles locales.

# Extras

¡Juega con tú modeol!

[Mayor información](https://github.com/ModelOriented/modelStudio/blob/master/README.md)

```{r, eval=FALSE}
library("modelStudio")

ms <- modelStudio(model_ranger, new_observation = Steve)
ms

library("arenar")
library("dplyr")

rownames(Steve) = c("Steve")

covid_ar <- create_arena(live = TRUE) %>%
    push_model(model_cdc) %>%
    push_model(model_tree) %>%
    push_model(model_ranger) %>%
    push_model(model_tuned) %>%
    push_observations(Steve) 
run_server(covid_ar)

```

# Información de la sesión

```{r, warning=FALSE, message=FALSE}
devtools::session_info()
```
